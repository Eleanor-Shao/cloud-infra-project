pipeline {
  agent any
  options {
    buildDiscarder(logRotator(numToKeepStr: '5'))
  }
  stages {
    stage('Scan') {
      steps {
        withCredentials([usernamePassword(credentialsId: 'SonarQubeToken', usernameVariable: 'SONAR_USER', passwordVariable: 'SONAR_PASS')]) {
          withSonarQubeEnv('SonarQube') { 
            sh './mvnw clean org.sonarsource.scanner.maven:sonar-maven-plugin:3.9.0.2155:sonar -Dsonar.projectKey="javawebapp" -Dsonar.login="$SONAR_USER" -Dsonar.password="$SONAR_PASS"'
          }
        }
      }
    }

    stage('Quality Gate') {
      steps {
        timeout(time: 1, unit: 'HOURS') {
          script {
            def qg = waitForQualityGate() // Checks SonarQube quality gate
            if (qg.status != 'OK') {
              error "Pipeline aborted due to quality gate failure: ${qg.status}"
            }
          }
        }
      }
    }
    // 格式化SonarQube结果，上传到GCS
    stage('Process SonarQube Results') {
      steps {
        script {
          // 调用SonarQube API获取分析结果
          sh 'curl -u $SONAR_USER:$SONAR_PASS "https://34.67.230.35:9000/api/issues/search?projectKeys=javawebapp" -o sonarqube_issues.json'

          // 调用Python脚本将结果格式化为MapReduce可处理的格式
          sh 'python format_sonarqube_issues.py sonarqube_issues.json sonarqube_issues.txt'

          // 上传格式化后的SonarQube结果到GCS
          sh 'gsutil cp sonarqube_issues.txt gs://hadoop-storage-bucket-final-project-437823/input-data/'
        }
      }
    }

    // 提交Hadoop MapReduce任务到Google Dataproc
    stage('Deploy to Dataproc') {
      when {
        expression {
          return currentBuild.result == null || currentBuild.result == 'SUCCESS'
        }
      }
      steps {
        withCredentials([file(credentialsId: 'gcp-service-account', variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
          script {
            // 验证GCP并提交Hadoop MapReduce任务
            sh """
              gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
              gcloud dataproc jobs submit hadoop \
                --cluster=hadoop-cluster \  
                --region=us-central1 \      
                --jar=gs://hadoop-storage-bucket-final-project-437823/wordcount-1.0-SNAPSHOT.jar \  
                --class=WordCount \ 
                -- gs://hadoop-storage-bucket-final-project-437823/input-data/ gs://hadoop-storage-bucket-final-project-437823/output-data/  
            """
          }
        }
      }
    }
  
  }
}

