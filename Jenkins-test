pipeline {
  agent any
    environment {
        HADOOP_MASTER_IP = "10.138.0.5"               // 从 Terraform 输出中获取
        HADOOP_USER = "hadoop"                                   // Hadoop 用户名
        SONAR_TOKEN = credentials('SonarQubeToken')                  // Jenkins 凭据中存储的 SonarQube token
        GCS_BUCKET_NAME = "hadoop-storage-bucket-project-440905"   // GCS 存储桶名称
        PROJECT_ID = "project-440905"                                // Google Cloud 项目 ID
        HADOOP_CLUSTER_NAME = "hadoop-cluster"            // Dataproc 集群名称
        HADOOP_REGION = "us-west1"                                 // Dataproc 集群区域
    }
  options {
    buildDiscarder(logRotator(numToKeepStr: '5'))
  }
  stages {
    stage('Scan') {
      steps {
        withCredentials([string(credentialsId: 'SonarQubeToken', variable: 'SONAR_TOKEN')]) {
          withSonarQubeEnv('SonarQube') { 
            sh '''
              ./mvnw clean org.sonarsource.scanner.maven:sonar-maven-plugin:3.9.0.2155:sonar \
                -Dsonar.projectKey="javawebapp" \
                -Dsonar.token="$SONAR_TOKEN"
            '''
          }
        }
      }
    }
    stage('Install Python') {
        steps {
            sh '''
            sudo apt-get update
            sudo apt-get install -y python3
            sudo ln -s /usr/bin/python3 /usr/bin/python
            '''
        }
    }
    stage('Install Google Cloud SDK') {
        steps {
            sh '''
            curl https://sdk.cloud.google.com | bash
            exec -l $SHELL
            gcloud components install -q
            gcloud init
            '''
        }
    }
    stage('Authenticate with Google Cloud') {
        steps {
            withCredentials([file(credentialsId: 'gcp-service-account-json', variable: 'GOOGLE_APPLICATION_CREDENTIALS')]) {
                sh '''
                gcloud auth activate-service-account --key-file=${GOOGLE_APPLICATION_CREDENTIALS}
                gcloud config set project ${PROJECT_ID}
                '''
            }
        }
    }
    stage('Deploy to Hadoop') {
        when {
            expression {
                currentBuild.result == null || currentBuild.result == 'SUCCESS'
            }
        }
        steps {
            script {
                // 使用 GCS 存储桶中的数据作为 Hadoop 作业的输入
                sh '''
                gcloud dataproc jobs submit hadoop \
                --cluster=${HADOOP_CLUSTER_NAME} \
                --region=${HADOOP_REGION} \
                --jar gs://${GCS_BUCKET_NAME}/wordcount-1.0-SNAPSHOT.jar \
                -- wordcount gs://${GCS_BUCKET_NAME}/input/input.txt gs://${GCS_BUCKET_NAME}/output/
                '''
            }
        }
    }
    stage('Display Hadoop Job Results') {
        steps {
            script {
                // 显示 Hadoop 作业输出结果到 Jenkins 控制台
                sh '''
                gcloud dataproc fs cat gs://${GCS_BUCKET_NAME}/output/part-*
                '''
            }
        }
    }
  }

}

